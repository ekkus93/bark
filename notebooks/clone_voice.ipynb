{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Use a T4 gpu for this*"
      ],
      "metadata": {
        "id": "CnqU3O1wp-Wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install required libraries"
      ],
      "metadata": {
        "id": "MRKyIJeGqxmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/ekkus93/bark.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WQaq7Ku1vFU",
        "outputId": "56a82fd1-b9f0-4030-c8ba-fce923419019"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ekkus93/bark.git\n",
            "  Cloning https://github.com/ekkus93/bark.git to /tmp/pip-req-build-x5o1ww8z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ekkus93/bark.git /tmp/pip-req-build-x5o1ww8z\n",
            "  Resolved https://github.com/ekkus93/bark.git to commit 8275b0dabab9138b5d78e71e5b5ec7647479fa4a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3 (from suno-bark==0.0.1a0)\n",
            "  Downloading boto3-1.34.145-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec (from suno-bark==0.0.1a0)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting funcy (from suno-bark==0.0.1a0)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (0.23.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.11.4)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (0.19.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (4.66.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (4.12.2)\n",
            "Collecting botocore<1.35.0,>=1.34.145 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading botocore-1.34.145-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from encodec->suno-bark==0.0.1a0) (2.3.1+cu121)\n",
            "Collecting einops (from encodec->suno-bark==0.0.1a0)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->suno-bark==0.0.1a0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (0.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.145->boto3->suno-bark==0.0.1a0) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.145->boto3->suno-bark==0.0.1a0) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->suno-bark==0.0.1a0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->suno-bark==0.0.1a0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.145->boto3->suno-bark==0.0.1a0) (1.16.0)\n",
            "Building wheels for collected packages: suno-bark, encodec\n",
            "  Building wheel for suno-bark (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suno-bark: filename=suno_bark-0.0.1a0-py3-none-any.whl size=2567357 sha256=da5e997768dced91660eab39dedf8e988da4718a684b25f4515d1582540643a2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9a6_watk/wheels/d3/94/a1/5b4b9d0c0b11b8463311db6bbe49c125d8cb5e41dc8b9553be\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45762 sha256=b6968eec6bdb2045acd0723ab192627847b10b4e8a3c74f8ef651e7cb17cd1f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "Successfully built suno-bark encodec\n",
            "Installing collected packages: funcy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, einops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, boto3, encodec, suno-bark\n",
            "Successfully installed boto3-1.34.145 botocore-1.34.145 einops-0.8.0 encodec-0.1.1 funcy-2.0 jmespath-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 s3transfer-0.10.2 suno-bark-0.0.1a0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY2J4I9O2knY",
        "outputId": "c6ed2026-c8de-408e-bc7e-43c4982d06ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
            "  Cloning https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer to /tmp/pip-req-build-qx0yr9pc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer /tmp/pip-req-build-qx0yr9pc\n",
            "  Resolved https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer to commit 4f42e44480fb076a52ddeb1f5ec6132d3c1ad25a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting audiolm-pytorch==1.1.4 (from bark-hubert-quantizer==0.0.4)\n",
            "  Downloading audiolm_pytorch-1.1.4-py3-none-any.whl (37 kB)\n",
            "Collecting fairseq (from bark-hubert-quantizer==0.0.4)\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from bark-hubert-quantizer==0.0.4) (0.23.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bark-hubert-quantizer==0.0.4) (0.1.99)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from bark-hubert-quantizer==0.0.4) (4.42.4)\n",
            "Requirement already satisfied: encodec in /usr/local/lib/python3.10/dist-packages (from bark-hubert-quantizer==0.0.4) (0.1.1)\n",
            "Collecting sox (from bark-hubert-quantizer==0.0.4)\n",
            "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (0.32.1)\n",
            "Collecting beartype (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading beartype-0.18.5-py3-none-any.whl (917 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.8/917.8 kB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (0.8.0)\n",
            "Collecting ema-pytorch>=0.2.2 (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading ema_pytorch-0.5.1-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (1.4.2)\n",
            "Collecting lion-pytorch (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading lion_pytorch-0.2.2-py3-none-any.whl (5.4 kB)\n",
            "Collecting local-attention>=1.8.4 (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading local_attention-1.9.14-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (4.66.4)\n",
            "Collecting vector-quantize-pytorch>=1.5.14 (from audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading vector_quantize_pytorch-1.15.3-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from encodec->bark-hubert-quantizer==0.0.4) (1.25.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->bark-hubert-quantizer==0.0.4) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->bark-hubert-quantizer==0.0.4) (3.0.10)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq->bark-hubert-quantizer==0.0.4) (2024.5.15)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray (from fairseq->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->bark-hubert-quantizer==0.0.4) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->bark-hubert-quantizer==0.0.4) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->bark-hubert-quantizer==0.0.4) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->bark-hubert-quantizer==0.0.4) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->bark-hubert-quantizer==0.0.4) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->bark-hubert-quantizer==0.0.4) (4.12.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bark-hubert-quantizer==0.0.4) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->bark-hubert-quantizer==0.0.4) (0.19.1)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->bark-hubert-quantizer==0.0.4) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->bark-hubert-quantizer==0.0.4) (4.9.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (12.5.82)\n",
            "Collecting einx>=0.2.2 (from vector-quantize-pytorch>=1.5.14->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4)\n",
            "  Downloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (5.9.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->bark-hubert-quantizer==0.0.4) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->bark-hubert-quantizer==0.0.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->bark-hubert-quantizer==0.0.4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->bark-hubert-quantizer==0.0.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->bark-hubert-quantizer==0.0.4) (2024.7.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (3.5.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from einx>=0.2.2->vector-quantize-pytorch>=1.5.14->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (2.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->audiolm-pytorch==1.1.4->bark-hubert-quantizer==0.0.4) (1.3.0)\n",
            "Building wheels for collected packages: bark-hubert-quantizer, fairseq, sox, antlr4-python3-runtime\n",
            "  Building wheel for bark-hubert-quantizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bark-hubert-quantizer: filename=bark_hubert_quantizer-0.0.4-py3-none-any.whl size=6533 sha256=c3bcac5e5c2e8a62a14f151a7a2c3b284227f6e7ac408760a07d5da7efee0702\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ql6wtt8u/wheels/b5/06/70/3c50dc359d4d38a37710f15e78de0142c3f52c3b71b89dfabb\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11289129 sha256=6ba5ddb8521c4abc158dab46189533d98d61f8d59fa0329d3406f85b2b879b40\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40038 sha256=2ddccb3d8184c54d9fed6eaf5a40ba3d5ced32a0897325558256164eb3fd66e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/e7/7b/8033be3ec5e4994595d01269fc9657c8fd83a0dcbf8536666a\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=9954bfb9c382292391d3d8ab610126b19cf2f10a4ef15b458468aa41c9b9d4b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built bark-hubert-quantizer fairseq sox antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, sox, portalocker, omegaconf, colorama, beartype, sacrebleu, hydra-core, einx, vector-quantize-pytorch, local-attention, lion-pytorch, ema-pytorch, fairseq, audiolm-pytorch, bark-hubert-quantizer\n",
            "Successfully installed antlr4-python3-runtime-4.8 audiolm-pytorch-1.1.4 bark-hubert-quantizer-0.0.4 beartype-0.18.5 bitarray-2.9.2 colorama-0.4.6 einx-0.3.0 ema-pytorch-0.5.1 fairseq-0.12.2 hydra-core-1.0.7 lion-pytorch-0.2.2 local-attention-1.9.14 omegaconf-2.0.6 portalocker-2.10.1 sacrebleu-2.4.2 sox-1.5.0 vector-quantize-pytorch-1.15.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Copy over hubert files into the content directory"
      ],
      "metadata": {
        "id": "CM5puIies5hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && wget https://github.com/ekkus93/bark/raw/main/hubert.zip && unzip hubert.zip"
      ],
      "metadata": {
        "id": "Aj9mS7M9tDGn",
        "outputId": "51192b71-2e3a-4e4e-f074-a1fdcf903168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-18 21:17:36--  https://github.com/ekkus93/bark/raw/main/hubert.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ekkus93/bark/main/hubert.zip [following]\n",
            "--2024-07-18 21:17:37--  https://raw.githubusercontent.com/ekkus93/bark/main/hubert.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4411 (4.3K) [application/zip]\n",
            "Saving to: ‘hubert.zip’\n",
            "\n",
            "hubert.zip          100%[===================>]   4.31K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-18 21:17:37 (46.4 MB/s) - ‘hubert.zip’ saved [4411/4411]\n",
            "\n",
            "Archive:  hubert.zip\n",
            "   creating: hubert/\n",
            "  inflating: hubert/customtokenizer.py  \n",
            "  inflating: hubert/hubert_manager.py  \n",
            "  inflating: hubert/pre_kmeans_hubert.py  \n",
            " extracting: hubert/__init__.py      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Setup"
      ],
      "metadata": {
        "id": "QSw4Da2CtXPR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ETTnEkIy1gOg"
      },
      "outputs": [],
      "source": [
        "from bark.generation import load_codec_model, generate_text_semantic\n",
        "from encodec.utils import convert_audio\n",
        "\n",
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "device = 'cuda' # or 'cpu'\n",
        "model = load_codec_model(use_gpu=True if device == 'cuda' else False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "a22c45971fed4bf8ad248ac7d007040a",
            "5a20b232b862493e97d313e57b183bba",
            "46f5397bd25f4d64a6f593a95c9ddb0c",
            "78d213dc716044f7a60124d6bafc2f9e",
            "d5178489cdb44b09a294978ff6237e19",
            "61a0df121e2142f49d5353cb7c9c5882",
            "b2ddf408766c4aa68903b42dc8267ad0",
            "a19de97b67f44b069fcf3a94610ffbdf",
            "ddd210f2accc49209bb1c8a13b8c1a82",
            "984fb1cd45194884b0f033f7773a1220",
            "48da99b9fde54d3ba5aa2ef84c71634d"
          ]
        },
        "id": "S8DnImKc1gOi",
        "outputId": "60450c53-a377-4f7f-f133-6c3621c64846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading HuBERT base model\n",
            "Downloaded HuBERT\n",
            "Downloading HuBERT custom tokenizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1194: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "quantifier_hubert_base_ls960_14.pth:   0%|          | 0.00/104M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a22c45971fed4bf8ad248ac7d007040a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded tokenizer\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/models/hubert/tokenizer.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "from hubert.hubert_manager import HuBERTManager\n",
        "hubert_manager = HuBERTManager()\n",
        "hubert_manager.make_sure_hubert_installed()\n",
        "hubert_manager.make_sure_tokenizer_installed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn0CBdQ31gOi",
        "outputId": "afcd9697-d92b-4df4-df63-447d0185c412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        }
      ],
      "source": [
        "# From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "# Load HuBERT for semantic tokens\n",
        "from hubert.pre_kmeans_hubert import CustomHubert\n",
        "from hubert.customtokenizer import CustomTokenizer\n",
        "\n",
        "# Load the HuBERT model\n",
        "hubert_model = CustomHubert(checkpoint_path='data/models/hubert/hubert.pt').to(device)\n",
        "\n",
        "# Load the CustomTokenizer model\n",
        "tokenizer = CustomTokenizer.load_from_checkpoint('data/models/hubert/tokenizer.pth').to(device)  # Automatically uses the right layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Get some wav files. The samples should be around 13 seconds. I found some videos on Youtube and used this site to extract the audio:\n",
        "https://tuberipper.com/25/\n",
        "\n",
        "Then I used Audacity to clean up the audio a bit and trim it down to around 13 seconds.\n",
        "Arnold:\n",
        "https://www.youtube.com/watch?v=0Oq_J6kfhos"
      ],
      "metadata": {
        "id": "dRz6wIDLu2QP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NmVTkDu1gOj"
      },
      "outputs": [],
      "source": [
        "# Load and pre-process the audio waveform\n",
        "#audio_filepath = 'audio.wav' # the audio you want to clone (under 13 seconds)\n",
        "audio_filepath = 'oh_wow_benefits.wav'\n",
        "wav, sr = torchaudio.load(audio_filepath)\n",
        "wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n",
        "wav = wav.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYArBuBh1gOj"
      },
      "outputs": [],
      "source": [
        "semantic_vectors = hubert_model.forward(wav, input_sample_hz=model.sample_rate)\n",
        "semantic_tokens = tokenizer.get_token(semantic_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOPDw44-1gOj"
      },
      "outputs": [],
      "source": [
        "# Extract discrete codes from EnCodec\n",
        "with torch.no_grad():\n",
        "    encoded_frames = model.encode(wav.unsqueeze(0))\n",
        "codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()  # [n_q, T]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COavxiYc1gOj"
      },
      "outputs": [],
      "source": [
        "# move codes to cpu\n",
        "codes = codes.cpu().numpy()\n",
        "# move semantic tokens to cpu\n",
        "semantic_tokens = semantic_tokens.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2CVLHL_1gOj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "voice_name = 'en_minah_1' # whatever you want the name of the voice to be\n",
        "#output_path = 'bark/assets/prompts/' + voice_name + '.npz'\n",
        "output_path = '/usr/local/lib/python3.10/dist-packages/bark/assets/prompts/' + voice_name + '.npz'\n",
        "\n",
        "np.savez(output_path, fine_prompt=codes, coarse_prompt=codes[:2, :], semantic_prompt=semantic_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbjoHN-f1gOk"
      },
      "outputs": [],
      "source": [
        "# That's it! Now you can head over to the generate.ipynb and use your voice_name for the 'history_prompt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFZJjfpu1gOk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlD-9AHS1gOk"
      },
      "outputs": [],
      "source": [
        "# Heres the generation stuff copy-pasted for convenience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI7eX63C1gOk"
      },
      "outputs": [],
      "source": [
        "from bark.api import generate_audio\n",
        "from transformers import BertTokenizer\n",
        "from bark.generation import SAMPLE_RATE, preload_models, codec_decode, generate_coarse, generate_fine, generate_text_semantic\n",
        "\n",
        "# Enter your prompt and speaker here\n",
        "text_prompt = \"Hello, my name is Minah. And, uh — and I like pizza. [laughs]\"\n",
        "voice_name = \"en_minah_1\" # use your custom voice name here if you have one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxpAPW3f1gOl"
      },
      "outputs": [],
      "source": [
        "# download and load all models\n",
        "preload_models(\n",
        "    text_use_gpu=True,\n",
        "    text_use_small=False,\n",
        "    coarse_use_gpu=True,\n",
        "    coarse_use_small=False,\n",
        "    fine_use_gpu=True,\n",
        "    fine_use_small=False,\n",
        "    codec_use_gpu=True,\n",
        "    force_reload=False,\n",
        "    #path=\"models\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e_Vm6DD1gOl"
      },
      "outputs": [],
      "source": [
        "# simple generation\n",
        "audio_array = generate_audio(text_prompt, history_prompt=voice_name, text_temp=0.7, waveform_temp=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOudAEn91gOl"
      },
      "outputs": [],
      "source": [
        "# generation with more control\n",
        "x_semantic = generate_text_semantic(\n",
        "    text_prompt,\n",
        "    history_prompt=voice_name,\n",
        "    temp=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        ")\n",
        "\n",
        "x_coarse_gen = generate_coarse(\n",
        "    x_semantic,\n",
        "    history_prompt=voice_name,\n",
        "    temp=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        ")\n",
        "x_fine_gen = generate_fine(\n",
        "    x_coarse_gen,\n",
        "    history_prompt=voice_name,\n",
        "    temp=0.5,\n",
        ")\n",
        "audio_array = codec_decode(x_fine_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kgNjAp11gOl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "# play audio\n",
        "Audio(audio_array, rate=SAMPLE_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWVxNAfJ1gOl"
      },
      "outputs": [],
      "source": [
        "from scipy.io.wavfile import write as write_wav\n",
        "# save audio\n",
        "#filepath = \"/output/audio.wav\" # change this to your desired output path\n",
        "filepath = \"output/audio.wav\"\n",
        "write_wav(filepath, SAMPLE_RATE, audio_array)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a22c45971fed4bf8ad248ac7d007040a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a20b232b862493e97d313e57b183bba",
              "IPY_MODEL_46f5397bd25f4d64a6f593a95c9ddb0c",
              "IPY_MODEL_78d213dc716044f7a60124d6bafc2f9e"
            ],
            "layout": "IPY_MODEL_d5178489cdb44b09a294978ff6237e19"
          }
        },
        "5a20b232b862493e97d313e57b183bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a0df121e2142f49d5353cb7c9c5882",
            "placeholder": "​",
            "style": "IPY_MODEL_b2ddf408766c4aa68903b42dc8267ad0",
            "value": "quantifier_hubert_base_ls960_14.pth: 100%"
          }
        },
        "46f5397bd25f4d64a6f593a95c9ddb0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a19de97b67f44b069fcf3a94610ffbdf",
            "max": 103981977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddd210f2accc49209bb1c8a13b8c1a82",
            "value": 103981977
          }
        },
        "78d213dc716044f7a60124d6bafc2f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984fb1cd45194884b0f033f7773a1220",
            "placeholder": "​",
            "style": "IPY_MODEL_48da99b9fde54d3ba5aa2ef84c71634d",
            "value": " 104M/104M [00:07&lt;00:00, 17.7MB/s]"
          }
        },
        "d5178489cdb44b09a294978ff6237e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a0df121e2142f49d5353cb7c9c5882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2ddf408766c4aa68903b42dc8267ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a19de97b67f44b069fcf3a94610ffbdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd210f2accc49209bb1c8a13b8c1a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "984fb1cd45194884b0f033f7773a1220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48da99b9fde54d3ba5aa2ef84c71634d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}